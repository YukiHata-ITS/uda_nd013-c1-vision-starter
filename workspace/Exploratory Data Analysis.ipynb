{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the dataset\n",
    "\n",
    "\n",
    "In this notebook, we will perform an EDA (Exploratory Data Analysis) on the processed Waymo dataset (data in the `processed` folder). In the first part, you will create a function to display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "            \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/waymo/training_and_validation/segment-1005081002024129653_5313_150_5333_150_with_camera_labels.tfrecord\n",
      "INFO:tensorflow:Reading unweighted datasets: ['data/waymo/training_and_validation/segment-1005081002024129653_5313_150_5333_150_with_camera_labels.tfrecord']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['data/waymo/training_and_validation/segment-1005081002024129653_5313_150_5333_150_with_camera_labels.tfrecord']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /data/virtual_envs/sdc-c1-gpu-augment/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /data/virtual_envs/sdc-c1-gpu-augment/lib/python3.7/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "-----------------------------------------------------------\n",
      "<DatasetV1Adapter shapes: {image: (None, None, 3), source_id: (), key: (), filename: (), groundtruth_image_confidences: (None,), groundtruth_verified_neg_classes: (None,), groundtruth_not_exhaustive_classes: (None,), groundtruth_boxes: (None, 4), groundtruth_area: (None,), groundtruth_is_crowd: (None,), groundtruth_difficult: (None,), groundtruth_group_of: (None,), groundtruth_weights: (None,), groundtruth_classes: (None,), groundtruth_image_classes: (None,), original_image_spatial_shape: (2,)}, types: {image: tf.uint8, source_id: tf.string, key: tf.string, filename: tf.string, groundtruth_image_confidences: tf.float32, groundtruth_verified_neg_classes: tf.int64, groundtruth_not_exhaustive_classes: tf.int64, groundtruth_boxes: tf.float32, groundtruth_area: tf.float32, groundtruth_is_crowd: tf.bool, groundtruth_difficult: tf.int64, groundtruth_group_of: tf.bool, groundtruth_weights: tf.float32, groundtruth_classes: tf.int64, groundtruth_image_classes: tf.int64, original_image_spatial_shape: tf.int32}>\n"
     ]
    }
   ],
   "source": [
    "paths = glob.glob('data/waymo/training_and_validation/*')\n",
    "i = 0\n",
    "#filename = os.path.basename(paths)\n",
    "print(paths[i])\n",
    "dataset = get_dataset(paths[i])\n",
    "print('-----------------------------------------------------------')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(dataset)\n",
    "\n",
    "```\n",
    "<\n",
    "\tDatasetV1Adapter shapes: \n",
    "\t{\n",
    "\t\timage: (None, None, 3), \n",
    "\t\tsource_id: (), \n",
    "\t\tkey: (), \n",
    "\t\tfilename: (), \n",
    "\t\tgroundtruth_image_confidences: (None,), \n",
    "\t\tgroundtruth_verified_neg_classes: (None,), \n",
    "\t\tgroundtruth_not_exhaustive_classes: (None,), \n",
    "\t\tgroundtruth_boxes: (None, 4), \n",
    "\t\tgroundtruth_area: (None,), \n",
    "\t\tgroundtruth_is_crowd: (None,), \n",
    "\t\tgroundtruth_difficult: (None,), \n",
    "\t\tgroundtruth_group_of: (None,), \n",
    "\t\tgroundtruth_weights: (None,), \n",
    "\t\tgroundtruth_classes: (None,), \n",
    "\t\tgroundtruth_image_classes: (None,), \n",
    "\t\toriginal_image_spatial_shape: (2,)\n",
    "\t}, \n",
    "\ttypes: \n",
    "\t{\n",
    "\t\timage: tf.uint8, \n",
    "\t\tsource_id: tf.string, \n",
    "\t\tkey: tf.string, \n",
    "\t\tfilename: tf.string, \n",
    "\t\tgroundtruth_image_confidences: tf.float32, \n",
    "\t\tgroundtruth_verified_neg_classes: tf.int64, \n",
    "\t\tgroundtruth_not_exhaustive_classes: tf.int64, \n",
    "\t\tgroundtruth_boxes: tf.float32, \n",
    "\t\tgroundtruth_area: tf.float32, \n",
    "\t\tgroundtruth_is_crowd: tf.bool, \n",
    "\t\tgroundtruth_difficult: tf.int64, \n",
    "\t\tgroundtruth_group_of: tf.bool, \n",
    "\t\tgroundtruth_weights: tf.float32, \n",
    "\t\tgroundtruth_classes: tf.int64, \n",
    "\t\tgroundtruth_image_classes: tf.int64, \n",
    "\t\toriginal_image_spatial_shape: tf.int32\n",
    "\t}\n",
    ">\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function to display an image and the bounding boxes\n",
    "\n",
    "Implement the `display_instances` function below. This function takes a batch as an input and display an image with its corresponding bounding boxes. The only requirement is that the classes should be color coded (eg, vehicles in red, pedestrians in blue, cyclist in green)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_instances(batch):\n",
    "    \"\"\"\n",
    "    This function takes a batch from the dataset and display the image with \n",
    "    the associated bounding boxes.\n",
    "    この関数は、データセットからバッチを取得し、関連する境界ボックスとともに画像を表示します。\n",
    "    \"\"\"\n",
    "    # ADD CODE HERE\n",
    "\n",
    "    ##### 色指定\n",
    "    # color for different classes\n",
    "    colormap = {1:'blue', 2:'green', 4:'red'}\n",
    "    \n",
    "    ##### サブプロット領域設定。2行×5列、画像サイズ=(20, 10)\n",
    "    num_col = 5\n",
    "    num_row = (len(batch) + num_col -1) // num_col\n",
    "    f, ax = plt.subplots(num_row, num_col, figsize=(20, 10))\n",
    "    \n",
    "    ##### batchのインデックスとデータ分ループ\n",
    "    for idx, batch_data in enumerate(batch):\n",
    "        ##### 画像データ取り出し\n",
    "        img = batch_data[\"image\"]\n",
    "        ##### サブプロット領域の位置(x, y)算出\n",
    "        x = idx // num_col\n",
    "        y = idx % num_col       \n",
    "        \n",
    "        ##### サブプロット領域に画像をセット\n",
    "        ax[x, y].imshow(img)\n",
    "        \n",
    "        ##### バウンディボックス、クラス取得\n",
    "        gt_boxes = batch_data[\"groundtruth_boxes\"]\n",
    "        gt_classes = batch_data[\"groundtruth_classes\"]\n",
    "        ##### データごとループ\n",
    "        for bb, obj_class in zip(gt_boxes, gt_classes):\n",
    "            ##### バウンディボックスのx,y位置取得、スケーリング\n",
    "            y1, x1, y2, x2 = bb\n",
    "            x1 *= img.shape[0]\n",
    "            y1 *= img.shape[1]\n",
    "            y2 *= img.shape[0]\n",
    "            x2 *= img.shape[1]\n",
    "            ##### バウンディボックスの描画データ作成\n",
    "            rec = Rectangle((x1, y1), x2-x1, y2-y1, facecolor='none', edgecolor=colormap[obj_class])\n",
    "            ##### 画像にバウンディボックス描画を追加\n",
    "            ax[x, y].add_patch(rec)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display 10 images \n",
    "\n",
    "Using the dataset created in the second cell and the function you just coded, display 10 random images with the associated bounding boxes. You can use the methods `take` and `shuffle` on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STUDENT SOLUTION HERE\n",
    "\n",
    "batch = dataset.shuffle(100).take(10)\n",
    "display_instances(list(batch.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This display is saved as the following image.  \n",
    "\n",
    "![Display_10_images](00_report_data\\Exploratory_Data_Analysis\\Display_10_images.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional EDA\n",
    "\n",
    "In this last part, you are free to perform any additional analysis of the dataset. What else would like to know about the data?\n",
    "For example, think about data distribution. So far, you have only looked at a single file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### データセットから100データ分取得\n",
    "batch = dataset.shuffle(100).take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### 画像群取得\n",
    "def get_images(batch):    \n",
    "    images = []\n",
    "    for idx, batch_data in enumerate(batch):\n",
    "        img = batch_data[\"image\"]\n",
    "        images.append(img)\n",
    "    return images\n",
    "    \n",
    "##### jpg画像保存\n",
    "def save_jpg(images, save_dir='jpg_images'):\n",
    "    for idx, img in enumerate(images):\n",
    "        file_dir = save_dir + '/image' + str(idx) + '.jpg'\n",
    "        print(type(img))\n",
    "        img = tf.image.encode_jpeg(img, format='rgb')\n",
    "        \n",
    "#        plt.imshow(img)\n",
    "#        plt.show()\n",
    "#        mpimg.imsave(file_dir, img)\n",
    "        cv2.imwrite(file_dir, img)\n",
    "#    mpimg.imsave(f'{save_dir}/{batch[\"filename\"].decode(\"utf-8\")}.jpg', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "##### main\n",
    "range = (0, 255)\n",
    "save_dir='jpg_images'\n",
    "images = get_images(batch)\n",
    "#save_jpg(images, save_dir)\n",
    "\n",
    "##### デバッグ\n",
    "#plt.imshow(images[0])\n",
    "#plt.show()\n",
    "print(type(images[0]))\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil2cv(image):\n",
    "    ''' PIL型 -> OpenCV型 '''\n",
    "    new_image = np.array(image, dtype=np.uint8)\n",
    "    if new_image.ndim == 2:  # モノクロ\n",
    "        pass\n",
    "    elif new_image.shape[2] == 3:  # カラー\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_RGB2BGR)\n",
    "    elif new_image.shape[2] == 4:  # 透過\n",
    "        new_image = cv2.cvtColor(new_image, cv2.COLOR_RGBA2BGRA)\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### jpg画像取得\n",
    "def open_jpg_images(image_dir):\n",
    "    images = glob.glob(image_dir)\n",
    "    jpg_images = [mpimg.imread(x) for x in images]\n",
    "    return jpg_images\n",
    "\n",
    "##### ヒストグラム表示\n",
    "def show_histogram(target_type, images, range=(0, 255)):\n",
    "#    images = [mpimg.imread(x) for x in images]\n",
    "#    images = [cv2.cvtColor(x, cv2.COLOR_RGB2BGR) for x in images]\n",
    "    plot_data = [target_type(img) for img in images]\n",
    "    plt.hist(plot_data, range=range, bins=20)\n",
    "    plt.show()\n",
    "\n",
    "def red_mean(img):\n",
    "    return img[...,0].numpy().mean()\n",
    "\n",
    "def green_mean(img):\n",
    "    return img[...,1].numpy().mean()\n",
    "\n",
    "def blue_mean(img):\n",
    "    return img[...,2].numpy().mean()\n",
    "\n",
    "def bright_value_mean(img):\n",
    "    img = pil2cv(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    return img[..., 2].mean()\n",
    "\n",
    "def hue_mean(img):\n",
    "    img = pil2cv(img)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    return img[..., 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'jpg_images/*.jpg'\n",
    "jpg_images = open_jpg_images(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_histogram(red_mean, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![red_histogram](00_report_data\\Exploratory_Data_Analysis\\red_histogram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_histogram(green_mean, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green_histogram](00_report_data\\Exploratory_Data_Analysis\\green_histogram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_histogram(blue_mean, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![blue_histogram](00_report_data\\Exploratory_Data_Analysis\\blue_histogram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_histogram(bright_value_mean, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bright_value_mean_histogram](00_report_data\\Exploratory_Data_Analysis\\bright_value_mean_histogram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_histogram(hue_mean, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hue_histogram](00_report_data\\Exploratory_Data_Analysis\\hue_histogram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### クラスごとのオブジェクト数調査"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### クラスごとのオブジェクト数取得\n",
    "def cnt_object_per_class(dataset):\n",
    "    ##### クラスごとのオブジェクト数カウンタ\n",
    "    obj_cnt_per_class = {1:0, 2:0, 4:0}\n",
    "\n",
    "    for data in dataset.take(20000):\n",
    "        for gt_c in data['groundtruth_classes'].numpy():\n",
    "            obj_cnt_per_class[gt_c] += 1   \n",
    "    return obj_cnt_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distributing data in bar graph\n",
    "def display_object_per_class(dataset):\n",
    "    ##### クラスごとのオブジェクト数取得\n",
    "    obj_cnt_per_class = cnt_object_per_class(dataset)\n",
    "    \n",
    "    ##### クラス名とオブジェクト数の紐づけ\n",
    "    obj_per_classes = {'vehicles':obj_cnt_per_class[1], 'pedestrians':obj_cnt_per_class[2],'cyclists':obj_cnt_per_class[4]}\n",
    "    classes_name = list(obj_per_classes.keys())\n",
    "\n",
    "    ##### オブジェクト数取得\n",
    "    num_of_object = [obj_per_classes[c] for c in classes_name]\n",
    "\n",
    "    ##### グラフ生成\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "    ##### グラフ設定、表示\n",
    "    plt.bar(classes_name,num_of_object,color=['blue','green','red'],width=0.4)\n",
    "    plt.xlabel(\"classes_name\")\n",
    "    plt.ylabel(\"num_of_object\")\n",
    "    plt.title(\"distribution of num of object per classes\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_object_per_class(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![object_per_class](00_report_data\\Exploratory_Data_Analysis\\object_per_class.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
