{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the dataset\n",
    "\n",
    "\n",
    "In this notebook, we will perform an EDA (Exploratory Data Analysis) on the processed Waymo dataset (data in the `processed` folder). In the first part, you will create a function to display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "            \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "\n",
    "##### add\n",
    "import cv2\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/waymo/training_and_validation/segment-1051897962568538022_238_170_258_170_with_camera_labels.tfrecord\n",
      "INFO:tensorflow:Reading unweighted datasets: ['data/waymo/training_and_validation/segment-1051897962568538022_238_170_258_170_with_camera_labels.tfrecord']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['data/waymo/training_and_validation/segment-1051897962568538022_238_170_258_170_with_camera_labels.tfrecord']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "-----------------------------------------------------------\n",
      "<DatasetV1Adapter shapes: {image: (None, None, 3), source_id: (), key: (), filename: (), groundtruth_image_confidences: (None,), groundtruth_verified_neg_classes: (None,), groundtruth_not_exhaustive_classes: (None,), groundtruth_boxes: (None, 4), groundtruth_area: (None,), groundtruth_is_crowd: (None,), groundtruth_difficult: (None,), groundtruth_group_of: (None,), groundtruth_weights: (None,), groundtruth_classes: (None,), groundtruth_image_classes: (None,), original_image_spatial_shape: (2,)}, types: {image: tf.uint8, source_id: tf.string, key: tf.string, filename: tf.string, groundtruth_image_confidences: tf.float32, groundtruth_verified_neg_classes: tf.int64, groundtruth_not_exhaustive_classes: tf.int64, groundtruth_boxes: tf.float32, groundtruth_area: tf.float32, groundtruth_is_crowd: tf.bool, groundtruth_difficult: tf.int64, groundtruth_group_of: tf.bool, groundtruth_weights: tf.float32, groundtruth_classes: tf.int64, groundtruth_image_classes: tf.int64, original_image_spatial_shape: tf.int32}>\n"
     ]
    }
   ],
   "source": [
    "paths = glob.glob('data/waymo/training_and_validation/*')\n",
    "i = 0\n",
    "#filename = os.path.basename(paths)\n",
    "print(paths[i])\n",
    "dataset = get_dataset(paths[i])\n",
    "print('-----------------------------------------------------------')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(dataset)\n",
    "\n",
    "```\n",
    "<\n",
    "\tDatasetV1Adapter shapes: \n",
    "\t{\n",
    "\t\timage: (None, None, 3), \n",
    "\t\tsource_id: (), \n",
    "\t\tkey: (), \n",
    "\t\tfilename: (), \n",
    "\t\tgroundtruth_image_confidences: (None,), \n",
    "\t\tgroundtruth_verified_neg_classes: (None,), \n",
    "\t\tgroundtruth_not_exhaustive_classes: (None,), \n",
    "\t\tgroundtruth_boxes: (None, 4), \n",
    "\t\tgroundtruth_area: (None,), \n",
    "\t\tgroundtruth_is_crowd: (None,), \n",
    "\t\tgroundtruth_difficult: (None,), \n",
    "\t\tgroundtruth_group_of: (None,), \n",
    "\t\tgroundtruth_weights: (None,), \n",
    "\t\tgroundtruth_classes: (None,), \n",
    "\t\tgroundtruth_image_classes: (None,), \n",
    "\t\toriginal_image_spatial_shape: (2,)\n",
    "\t}, \n",
    "\ttypes: \n",
    "\t{\n",
    "\t\timage: tf.uint8, \n",
    "\t\tsource_id: tf.string, \n",
    "\t\tkey: tf.string, \n",
    "\t\tfilename: tf.string, \n",
    "\t\tgroundtruth_image_confidences: tf.float32, \n",
    "\t\tgroundtruth_verified_neg_classes: tf.int64, \n",
    "\t\tgroundtruth_not_exhaustive_classes: tf.int64, \n",
    "\t\tgroundtruth_boxes: tf.float32, \n",
    "\t\tgroundtruth_area: tf.float32, \n",
    "\t\tgroundtruth_is_crowd: tf.bool, \n",
    "\t\tgroundtruth_difficult: tf.int64, \n",
    "\t\tgroundtruth_group_of: tf.bool, \n",
    "\t\tgroundtruth_weights: tf.float32, \n",
    "\t\tgroundtruth_classes: tf.int64, \n",
    "\t\tgroundtruth_image_classes: tf.int64, \n",
    "\t\toriginal_image_spatial_shape: tf.int32\n",
    "\t}\n",
    ">\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a function to display an image and the bounding boxes\n",
    "\n",
    "Implement the `display_instances` function below. This function takes a batch as an input and display an image with its corresponding bounding boxes. The only requirement is that the classes should be color coded (eg, vehicles in red, pedestrians in blue, cyclist in green)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_instances(batch):\n",
    "    \"\"\"\n",
    "    This function takes a batch from the dataset and display the image with \n",
    "    the associated bounding boxes.\n",
    "    この関数は、データセットからバッチを取得し、関連する境界ボックスとともに画像を表示します。\n",
    "    \"\"\"\n",
    "    # ADD CODE HERE\n",
    "\n",
    "    ##### 色指定\n",
    "    # color for different classes\n",
    "#    colormap = {1: [1, 0 , 0], 2: [0, 0, 1], 4: [0, 1, 0]}\n",
    "    colormap = {1:'blue', 2:'green', 4:'red'}\n",
    "    \n",
    "    ##### サブプロット領域設定。1×2、画像サイズ=(10, 10)\n",
    "    num_col = 5\n",
    "    num_row = (len(batch) + num_col -1) // num_col\n",
    "    f, ax = plt.subplots(num_row, num_col, figsize=(20, 10))\n",
    "    \n",
    "    ##### batchのインデックスと中身を反復子にしてループ\n",
    "    for idx, batch_data in enumerate(batch):\n",
    "        img = batch_data[\"image\"]\n",
    "        x = idx // num_col\n",
    "        y = idx % num_col       \n",
    "        \n",
    "        ##### 画像をセット\n",
    "        ax[x, y].imshow(img)\n",
    "        \n",
    "        ##### バウンディボックス\n",
    "        gt_boxes = batch_data[\"groundtruth_boxes\"]\n",
    "        gt_classes = batch_data[\"groundtruth_classes\"]\n",
    "        for bb, obj_class in zip(gt_boxes, gt_classes):\n",
    "            y1, x1, y2, x2 = bb\n",
    "            x1 *= img.shape[0]\n",
    "            y1 *= img.shape[1]\n",
    "            y2 *= img.shape[0]\n",
    "            x2 *= img.shape[1]\n",
    "            rec = Rectangle((x1, y1), x2-x1, y2-y1, facecolor='none', edgecolor=colormap[obj_class])\n",
    "#            rec = Rectangle((x1, y1), x2-x1, y2-y1, facecolor='none', edgecolor='r')\n",
    "            ax[x, y].add_patch(rec)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display 10 images \n",
    "\n",
    "Using the dataset created in the second cell and the function you just coded, display 10 random images with the associated bounding boxes. You can use the methods `take` and `shuffle` on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STUDENT SOLUTION HERE\n",
    "\n",
    "batch = dataset.shuffle(10).take(10)\n",
    "display_instances(list(batch.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional EDA\n",
    "\n",
    "In this last part, you are free to perform any additional analysis of the dataset. What else would like to know about the data?\n",
    "For example, think about data distribution. So far, you have only looked at a single file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#batch = dataset.shuffle(10).take(10)\n",
    "\n",
    "##### 画像群取得\n",
    "def get_images(batch):    \n",
    "    images = []\n",
    "    for idx, batch_data in enumerate(batch):\n",
    "        img = batch_data[\"image\"]\n",
    "        images.append(img)\n",
    "    return images\n",
    "    \n",
    "images = get_images(batch)\n",
    "\n",
    "##### kakuninn\n",
    "#plt.imshow(images[0])\n",
    "#plt.show()\n",
    "print(type(images[0]))\n",
    "print(len(images))\n",
    "range = (0, 255)\n",
    "#print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected Ptr<cv::UMat> for argument 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-0281bf5b2a8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhsv_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2HSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Expected Ptr<cv::UMat> for argument 'src'"
     ]
    }
   ],
   "source": [
    "hsv_image = cv2.cvtColor(images[0], cv2.COLOR_RGB2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-8105773e2e59>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-8105773e2e59>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    gt_classes.(batch[\"groundtruth_classes\"].numpy())\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_cnt_class(dataset, num_dataset =100):\n",
    "    gt_classes = np.array([])\n",
    "    ##### 真値(gt)をバッチから抽出して classes に追加\n",
    "    for batch in dataset.take(num_dataset):\n",
    "#        gt_classes = np.append(gt_classes, batch[\"groundtruth_classes\"].numpy())\n",
    "        gt_classes.(batch[\"groundtruth_classes\"].numpy())\n",
    "    print(gt_classes)\n",
    "    return np.unique(gt_classes, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "gt_classes, count = get_cnt_class(dataset, 100)\n",
    "\n",
    "class_names = ['vehicle', 'pedestrian', 'cyclist']\n",
    "plt.bar(left=range(len(classes)), height=count, tick_label=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    for idx, batch_data in enumerate(batch):\n",
    "#        img = batch_data[\"image\"]\n",
    "\n",
    "\n",
    "# ヒストグラム表示\n",
    "def histogram(fn, images, range=(0, 255)):\n",
    "#    images = [mpimg.imread(x) for x in images]\n",
    "    images = [cv2.cvtColor(x, cv2.COLOR_RGB2BGR) for x in images]\n",
    "    output = [fn(x) for x in images]\n",
    "    plt.hist(output, range=range, bins=20)\n",
    "\n",
    "def bright(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)[..., 2].mean()\n",
    "\n",
    "def blue(img):\n",
    "    return img[...,0].mean()\n",
    "\n",
    "def green(img):\n",
    "    return img[...,1].mean()\n",
    "\n",
    "def red(img):\n",
    "    return img[...,2].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected Ptr<cv::UMat> for argument 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-b41d5cfd2b58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-654d9097ca2f>\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(fn, images, range)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#    images = [mpimg.imread(x) for x in images]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-654d9097ca2f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#    images = [mpimg.imread(x) for x in images]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected Ptr<cv::UMat> for argument 'src'"
     ]
    }
   ],
   "source": [
    "print(histogram(blue, images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram(bright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': <tf.Tensor: shape=(640, 640, 3), dtype=uint8, numpy=\n",
      "array([[[190, 220, 255],\n",
      "        [191, 221, 255],\n",
      "        [191, 221, 255],\n",
      "        ...,\n",
      "        [ 56,  77,  80],\n",
      "        [ 63,  81,  95],\n",
      "        [ 48,  65,  85]],\n",
      "\n",
      "       [[185, 215, 253],\n",
      "        [187, 217, 253],\n",
      "        [188, 218, 252],\n",
      "        ...,\n",
      "        [ 52,  73,  74],\n",
      "        [114, 134, 145],\n",
      "        [ 45,  64,  81]],\n",
      "\n",
      "       [[179, 208, 248],\n",
      "        [181, 211, 249],\n",
      "        [183, 213, 249],\n",
      "        ...,\n",
      "        [ 44,  65,  66],\n",
      "        [ 52,  72,  79],\n",
      "        [ 46,  68,  79]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 86,  85,  93],\n",
      "        [ 85,  84,  92],\n",
      "        [ 83,  82,  90],\n",
      "        ...,\n",
      "        [ 62,  57,  64],\n",
      "        [ 65,  59,  69],\n",
      "        [ 57,  51,  61]],\n",
      "\n",
      "       [[ 85,  85,  93],\n",
      "        [ 84,  84,  92],\n",
      "        [ 84,  84,  92],\n",
      "        ...,\n",
      "        [ 62,  54,  65],\n",
      "        [ 60,  52,  63],\n",
      "        [ 58,  50,  61]],\n",
      "\n",
      "       [[ 82,  82,  90],\n",
      "        [ 83,  83,  91],\n",
      "        [ 84,  84,  92],\n",
      "        ...,\n",
      "        [ 62,  54,  65],\n",
      "        [ 57,  49,  60],\n",
      "        [ 61,  53,  64]]], dtype=uint8)>, 'source_id': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_140.tfrecord'>, 'key': <tf.Tensor: shape=(), dtype=string, numpy=b''>, 'filename': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_140.tfrecord'>, 'groundtruth_image_confidences': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_verified_neg_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_not_exhaustive_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_boxes': <tf.Tensor: shape=(21, 4), dtype=float32, numpy=\n",
      "array([[0.53586465, 0.40033597, 0.5881682 , 0.44441566],\n",
      "       [0.5250092 , 0.5024759 , 0.5398121 , 0.51398927],\n",
      "       [0.515634  , 0.5873458 , 0.51958144, 0.59425384],\n",
      "       [0.52185154, 0.498594  , 0.5307333 , 0.505502  ],\n",
      "       [0.5600427 , 0.2583927 , 0.68438697, 0.3725394 ],\n",
      "       [0.56941783, 0.10411366, 0.68093294, 0.23339224],\n",
      "       [0.5405522 , 0.46020544, 0.6347973 , 0.5286277 ],\n",
      "       [0.52624273, 0.45510665, 0.5326573 , 0.45938304],\n",
      "       [0.5274763 , 0.45148817, 0.5324106 , 0.45708036],\n",
      "       [0.5351245 , 0.39836225, 0.5652237 , 0.41349408],\n",
      "       [0.5274763 , 0.39605957, 0.53142375, 0.39869118],\n",
      "       [0.5229862 , 0.4576559 , 0.54173654, 0.47275493],\n",
      "       [0.52624273, 0.47402146, 0.5385785 , 0.48257422],\n",
      "       [0.5220486 , 0.519417  , 0.5279698 , 0.52928555],\n",
      "       [0.5287099 , 0.4133296 , 0.5351245 , 0.42484295],\n",
      "       [0.51588076, 0.59688544, 0.53611135, 0.6169516 ],\n",
      "       [0.5383318 , 0.4898112 , 0.5531347 , 0.5200749 ],\n",
      "       [0.5218019 , 0.51826566, 0.5282165 , 0.529779  ],\n",
      "       [0.50576496, 0.48331487, 0.5363572 , 0.49828213],\n",
      "       [0.52426904, 0.4784623 , 0.53068364, 0.4827387 ],\n",
      "       [0.5255026 , 0.4384945 , 0.52945006, 0.44112614]], dtype=float32)>, 'groundtruth_area': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_is_crowd': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_difficult': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_group_of': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_weights': <tf.Tensor: shape=(21,), dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1.], dtype=float32)>, 'groundtruth_classes': <tf.Tensor: shape=(21,), dtype=int64, numpy=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])>, 'groundtruth_image_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'original_image_spatial_shape': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([640, 640], dtype=int32)>}\n",
      "{'image': <tf.Tensor: shape=(640, 640, 3), dtype=uint8, numpy=\n",
      "array([[[161, 193, 250],\n",
      "        [163, 196, 250],\n",
      "        [169, 200, 255],\n",
      "        ...,\n",
      "        [ 72,  80,  82],\n",
      "        [ 73,  79,  79],\n",
      "        [ 68,  74,  74]],\n",
      "\n",
      "       [[155, 190, 248],\n",
      "        [159, 194, 250],\n",
      "        [161, 194, 248],\n",
      "        ...,\n",
      "        [ 74,  82,  84],\n",
      "        [ 70,  79,  78],\n",
      "        [ 67,  76,  75]],\n",
      "\n",
      "       [[149, 185, 245],\n",
      "        [154, 190, 250],\n",
      "        [157, 193, 251],\n",
      "        ...,\n",
      "        [ 71,  81,  82],\n",
      "        [ 76,  86,  85],\n",
      "        [ 65,  75,  74]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 76,  76,  86],\n",
      "        [ 77,  77,  87],\n",
      "        [ 75,  75,  85],\n",
      "        ...,\n",
      "        [ 71,  85,  96],\n",
      "        [ 71,  85,  96],\n",
      "        [ 74,  88,  99]],\n",
      "\n",
      "       [[ 76,  76,  86],\n",
      "        [ 78,  78,  88],\n",
      "        [ 76,  76,  86],\n",
      "        ...,\n",
      "        [ 70,  84,  95],\n",
      "        [ 66,  83,  93],\n",
      "        [ 69,  86,  96]],\n",
      "\n",
      "       [[ 75,  75,  85],\n",
      "        [ 77,  77,  87],\n",
      "        [ 76,  76,  86],\n",
      "        ...,\n",
      "        [ 77,  91, 102],\n",
      "        [ 70,  87,  97],\n",
      "        [ 72,  89,  99]]], dtype=uint8)>, 'source_id': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_180.tfrecord'>, 'key': <tf.Tensor: shape=(), dtype=string, numpy=b''>, 'filename': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_180.tfrecord'>, 'groundtruth_image_confidences': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_verified_neg_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_not_exhaustive_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_boxes': <tf.Tensor: shape=(21, 4), dtype=float32, numpy=\n",
      "array([[0.5321708 , 0.40444738, 0.58250064, 0.44622442],\n",
      "       [0.525996  , 0.50000876, 0.5388252 , 0.5098773 ],\n",
      "       [0.51242673, 0.65214956, 0.52278876, 0.68800545],\n",
      "       [0.5131669 , 0.75609875, 0.5220486 , 0.7860335 ],\n",
      "       [0.51958144, 0.49310073, 0.52945006, 0.5016535 ],\n",
      "       [0.55634195, 0.33849275, 0.68414026, 0.44638938],\n",
      "       [0.5519058 , 0.21998993, 0.6328254 , 0.30699682],\n",
      "       [0.5400588 , 0.46415287, 0.62246156, 0.525996  ],\n",
      "       [0.5279698 , 0.37599343, 0.5368515 , 0.39244106],\n",
      "       [0.5230423 , 0.44096047, 0.53044236, 0.44721007],\n",
      "       [0.52377564, 0.43421814, 0.53019017, 0.4401393 ],\n",
      "       [0.5319172 , 0.4055992 , 0.5506675 , 0.414152  ],\n",
      "       [0.5235289 , 0.34967718, 0.53635806, 0.35822996],\n",
      "       [0.51218003, 0.80313903, 0.5250092 , 0.8883379 ],\n",
      "       [0.52303547, 0.45494217, 0.54079896, 0.4681003 ],\n",
      "       [0.5257493 , 0.4681003 , 0.5380851 , 0.47665307],\n",
      "       [0.52278876, 0.38553306, 0.53117704, 0.40198073],\n",
      "       [0.4887421 , 0.87468636, 0.59877694, 1.        ],\n",
      "       [0.53561795, 0.48306766, 0.5440062 , 0.5037917 ],\n",
      "       [0.50429237, 0.476406  , 0.5378456 , 0.49137312],\n",
      "       [0.5215552 , 0.4694161 , 0.5274763 , 0.47599518]], dtype=float32)>, 'groundtruth_area': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_is_crowd': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_difficult': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_group_of': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_weights': <tf.Tensor: shape=(21,), dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1.], dtype=float32)>, 'groundtruth_classes': <tf.Tensor: shape=(21,), dtype=int64, numpy=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])>, 'groundtruth_image_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'original_image_spatial_shape': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([640, 640], dtype=int32)>}\n",
      "{'image': <tf.Tensor: shape=(640, 640, 3), dtype=uint8, numpy=\n",
      "array([[[129, 148, 181],\n",
      "        [126, 145, 177],\n",
      "        [142, 159, 189],\n",
      "        ...,\n",
      "        [118, 175, 246],\n",
      "        [118, 175, 246],\n",
      "        [118, 175, 246]],\n",
      "\n",
      "       [[125, 144, 176],\n",
      "        [135, 154, 184],\n",
      "        [128, 145, 171],\n",
      "        ...,\n",
      "        [118, 175, 246],\n",
      "        [118, 175, 246],\n",
      "        [118, 175, 246]],\n",
      "\n",
      "       [[129, 146, 172],\n",
      "        [128, 146, 170],\n",
      "        [126, 143, 163],\n",
      "        ...,\n",
      "        [119, 176, 247],\n",
      "        [119, 176, 247],\n",
      "        [119, 176, 247]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 71,  72,  77],\n",
      "        [ 72,  73,  78],\n",
      "        [ 72,  73,  78],\n",
      "        ...,\n",
      "        [ 82,  91,  98],\n",
      "        [ 82,  91,  98],\n",
      "        [ 82,  91,  98]],\n",
      "\n",
      "       [[ 72,  73,  78],\n",
      "        [ 71,  72,  77],\n",
      "        [ 73,  73,  81],\n",
      "        ...,\n",
      "        [ 82,  91,  98],\n",
      "        [ 85,  94, 101],\n",
      "        [ 86,  95, 102]],\n",
      "\n",
      "       [[ 73,  74,  79],\n",
      "        [ 71,  72,  77],\n",
      "        [ 73,  73,  81],\n",
      "        ...,\n",
      "        [ 84,  93, 100],\n",
      "        [ 86,  95, 102],\n",
      "        [ 82,  91,  98]]], dtype=uint8)>, 'source_id': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_90.tfrecord'>, 'key': <tf.Tensor: shape=(), dtype=string, numpy=b''>, 'filename': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_90.tfrecord'>, 'groundtruth_image_confidences': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_verified_neg_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_not_exhaustive_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_boxes': <tf.Tensor: shape=(12, 4), dtype=float32, numpy=\n",
      "array([[0.5335206 , 0.3921945 , 0.590018  , 0.4397282 ],\n",
      "       [0.5250092 , 0.49836397, 0.5398121 , 0.5115221 ],\n",
      "       [0.5194583 , 0.49606133, 0.52834004, 0.50264037],\n",
      "       [0.5602894 , 0.20164827, 0.69894314, 0.32928208],\n",
      "       [0.54277265, 0.43175098, 0.66020894, 0.51694983],\n",
      "       [0.52303547, 0.463166  , 0.52895665, 0.46645552],\n",
      "       [0.52081496, 0.46648833, 0.5272295 , 0.47208053],\n",
      "       [0.5368515 , 0.3741842 , 0.5733653 , 0.40082937],\n",
      "       [0.52377564, 0.44852757, 0.5440062 , 0.4659621 ],\n",
      "       [0.5257493 , 0.46777135, 0.53611135, 0.47698203],\n",
      "       [0.5398121 , 0.48685062, 0.5852076 , 0.52171963],\n",
      "       [0.5077391 , 0.48553482, 0.53635806, 0.49803504]], dtype=float32)>, 'groundtruth_area': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_is_crowd': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_difficult': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_group_of': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_weights': <tf.Tensor: shape=(12,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, 'groundtruth_classes': <tf.Tensor: shape=(12,), dtype=int64, numpy=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])>, 'groundtruth_image_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'original_image_spatial_shape': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([640, 640], dtype=int32)>}\n",
      "{'image': <tf.Tensor: shape=(640, 640, 3), dtype=uint8, numpy=\n",
      "array([[[ 85,  83,  70],\n",
      "        [ 86,  84,  71],\n",
      "        [ 89,  90,  76],\n",
      "        ...,\n",
      "        [123, 182, 252],\n",
      "        [121, 180, 250],\n",
      "        [121, 180, 250]],\n",
      "\n",
      "       [[ 85,  83,  70],\n",
      "        [ 87,  85,  72],\n",
      "        [ 89,  90,  76],\n",
      "        ...,\n",
      "        [125, 184, 254],\n",
      "        [123, 182, 252],\n",
      "        [124, 183, 253]],\n",
      "\n",
      "       [[ 79,  77,  65],\n",
      "        [ 81,  79,  67],\n",
      "        [ 85,  83,  70],\n",
      "        ...,\n",
      "        [125, 184, 254],\n",
      "        [123, 183, 253],\n",
      "        [124, 184, 254]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 70,  74,  77],\n",
      "        [ 70,  74,  77],\n",
      "        [ 69,  72,  77],\n",
      "        ...,\n",
      "        [ 60,  54,  56],\n",
      "        [ 62,  58,  59],\n",
      "        [ 59,  57,  58]],\n",
      "\n",
      "       [[ 70,  74,  77],\n",
      "        [ 70,  74,  77],\n",
      "        [ 69,  73,  76],\n",
      "        ...,\n",
      "        [ 59,  53,  55],\n",
      "        [ 59,  55,  56],\n",
      "        [ 62,  58,  59]],\n",
      "\n",
      "       [[ 70,  74,  77],\n",
      "        [ 70,  74,  77],\n",
      "        [ 70,  74,  77],\n",
      "        ...,\n",
      "        [ 69,  63,  65],\n",
      "        [ 67,  63,  64],\n",
      "        [ 73,  69,  70]]], dtype=uint8)>, 'source_id': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_30.tfrecord'>, 'key': <tf.Tensor: shape=(), dtype=string, numpy=b''>, 'filename': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_30.tfrecord'>, 'groundtruth_image_confidences': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_verified_neg_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_not_exhaustive_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_boxes': <tf.Tensor: shape=(13, 4), dtype=float32, numpy=\n",
      "array([[0.53596306, 0.39385515, 0.59221375, 0.44234297],\n",
      "       [0.52343035, 0.49770573, 0.54139096, 0.5128376 ],\n",
      "       [0.57237774, 0.17697401, 0.7529744 , 0.34326097],\n",
      "       [0.54129237, 0.4534619 , 0.6389915 , 0.52681845],\n",
      "       [0.5188415 , 0.4690872 , 0.5245159 , 0.47303465],\n",
      "       [0.5383318 , 0.3557628 , 0.58076674, 0.39688194],\n",
      "       [0.5252559 , 0.6261623 , 0.58397406, 0.6455705 ],\n",
      "       [0.52426916, 0.43750772, 0.54894066, 0.45691594],\n",
      "       [0.5232822 , 0.46546867, 0.53561795, 0.47467935],\n",
      "       [0.5369336 , 0.57555807, 0.55354583, 0.58235645],\n",
      "       [0.5379619 , 0.5847154 , 0.5564663 , 0.5932682 ],\n",
      "       [0.5072457 , 0.4870151 , 0.5319172 , 0.5044496 ],\n",
      "       [0.5184709 , 0.5639082 , 0.5483241 , 0.57394123]], dtype=float32)>, 'groundtruth_area': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_is_crowd': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_difficult': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_group_of': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_weights': <tf.Tensor: shape=(13,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, 'groundtruth_classes': <tf.Tensor: shape=(13,), dtype=int64, numpy=array([1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2])>, 'groundtruth_image_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'original_image_spatial_shape': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([640, 640], dtype=int32)>}\n",
      "{'image': <tf.Tensor: shape=(640, 640, 3), dtype=uint8, numpy=\n",
      "array([[[169, 201, 252],\n",
      "        [170, 202, 251],\n",
      "        [174, 204, 254],\n",
      "        ...,\n",
      "        [136, 197, 251],\n",
      "        [136, 197, 251],\n",
      "        [136, 197, 251]],\n",
      "\n",
      "       [[173, 205, 255],\n",
      "        [171, 203, 252],\n",
      "        [173, 204, 251],\n",
      "        ...,\n",
      "        [135, 196, 250],\n",
      "        [134, 195, 249],\n",
      "        [133, 194, 248]],\n",
      "\n",
      "       [[167, 201, 249],\n",
      "        [165, 199, 247],\n",
      "        [168, 200, 247],\n",
      "        ...,\n",
      "        [137, 198, 252],\n",
      "        [137, 198, 252],\n",
      "        [137, 198, 252]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 79,  79,  87],\n",
      "        [ 80,  80,  88],\n",
      "        [ 79,  79,  87],\n",
      "        ...,\n",
      "        [ 95,  93,  96],\n",
      "        [111, 109, 112],\n",
      "        [ 95,  93,  96]],\n",
      "\n",
      "       [[ 74,  74,  82],\n",
      "        [ 78,  78,  86],\n",
      "        [ 81,  81,  89],\n",
      "        ...,\n",
      "        [ 88,  83,  87],\n",
      "        [ 94,  90,  91],\n",
      "        [ 96,  92,  93]],\n",
      "\n",
      "       [[ 76,  76,  84],\n",
      "        [ 76,  76,  84],\n",
      "        [ 76,  76,  84],\n",
      "        ...,\n",
      "        [ 94,  89,  93],\n",
      "        [ 84,  80,  81],\n",
      "        [ 83,  79,  80]]], dtype=uint8)>, 'source_id': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_190.tfrecord'>, 'key': <tf.Tensor: shape=(), dtype=string, numpy=b''>, 'filename': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_190.tfrecord'>, 'groundtruth_image_confidences': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_verified_neg_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_not_exhaustive_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_boxes': <tf.Tensor: shape=(18, 4), dtype=float32, numpy=\n",
      "array([[0.51933473, 0.40050042, 0.5484471 , 0.44293538],\n",
      "       [0.508726  , 0.4947455 , 0.5235289 , 0.5072457 ],\n",
      "       [0.49244282, 0.69178843, 0.5072457 , 0.743763  ],\n",
      "       [0.50601214, 0.48734406, 0.5163742 , 0.4955679 ],\n",
      "       [0.54314244, 0.3781307 , 0.66723996, 0.47780383],\n",
      "       [0.54079896, 0.23602387, 0.61580026, 0.31201205],\n",
      "       [0.5235289 , 0.45905408, 0.6014908 , 0.5172788 ],\n",
      "       [0.51736104, 0.3809277 , 0.5277231 , 0.39869118],\n",
      "       [0.51143986, 0.4329023 , 0.5198282 , 0.43882346],\n",
      "       [0.51143986, 0.42434952, 0.5198282 , 0.4309286 ],\n",
      "       [0.5210618 , 0.40395445, 0.54079896, 0.41382304],\n",
      "       [0.5151406 , 0.33026895, 0.52994347, 0.34276915],\n",
      "       [0.5097129 , 0.44819865, 0.5274763 , 0.46168572],\n",
      "       [0.51143986, 0.46497524, 0.52377564, 0.47319907],\n",
      "       [0.5131669 , 0.3782961 , 0.5220486 , 0.3881647 ],\n",
      "       [0.52278876, 0.4694161 , 0.53117704, 0.4977061 ],\n",
      "       [0.49268955, 0.47138983, 0.52377564, 0.48652166],\n",
      "       [0.51168656, 0.4661266 , 0.515634  , 0.47204775]], dtype=float32)>, 'groundtruth_area': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_is_crowd': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_difficult': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_group_of': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_weights': <tf.Tensor: shape=(18,), dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1.], dtype=float32)>, 'groundtruth_classes': <tf.Tensor: shape=(18,), dtype=int64, numpy=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])>, 'groundtruth_image_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'original_image_spatial_shape': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([640, 640], dtype=int32)>}\n",
      "{'image': <tf.Tensor: shape=(640, 640, 3), dtype=uint8, numpy=\n",
      "array([[[161, 193, 250],\n",
      "        [163, 196, 250],\n",
      "        [169, 200, 255],\n",
      "        ...,\n",
      "        [ 72,  80,  82],\n",
      "        [ 73,  79,  79],\n",
      "        [ 68,  74,  74]],\n",
      "\n",
      "       [[155, 190, 248],\n",
      "        [159, 194, 250],\n",
      "        [161, 194, 248],\n",
      "        ...,\n",
      "        [ 74,  82,  84],\n",
      "        [ 70,  79,  78],\n",
      "        [ 67,  76,  75]],\n",
      "\n",
      "       [[149, 185, 245],\n",
      "        [154, 190, 250],\n",
      "        [157, 193, 251],\n",
      "        ...,\n",
      "        [ 71,  81,  82],\n",
      "        [ 76,  86,  85],\n",
      "        [ 65,  75,  74]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 76,  76,  86],\n",
      "        [ 77,  77,  87],\n",
      "        [ 75,  75,  85],\n",
      "        ...,\n",
      "        [ 71,  85,  96],\n",
      "        [ 71,  85,  96],\n",
      "        [ 74,  88,  99]],\n",
      "\n",
      "       [[ 76,  76,  86],\n",
      "        [ 78,  78,  88],\n",
      "        [ 76,  76,  86],\n",
      "        ...,\n",
      "        [ 70,  84,  95],\n",
      "        [ 66,  83,  93],\n",
      "        [ 69,  86,  96]],\n",
      "\n",
      "       [[ 75,  75,  85],\n",
      "        [ 77,  77,  87],\n",
      "        [ 76,  76,  86],\n",
      "        ...,\n",
      "        [ 77,  91, 102],\n",
      "        [ 70,  87,  97],\n",
      "        [ 72,  89,  99]]], dtype=uint8)>, 'source_id': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_180.tfrecord'>, 'key': <tf.Tensor: shape=(), dtype=string, numpy=b''>, 'filename': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_180.tfrecord'>, 'groundtruth_image_confidences': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_verified_neg_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_not_exhaustive_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_boxes': <tf.Tensor: shape=(21, 4), dtype=float32, numpy=\n",
      "array([[0.5321708 , 0.40444738, 0.58250064, 0.44622442],\n",
      "       [0.525996  , 0.50000876, 0.5388252 , 0.5098773 ],\n",
      "       [0.51242673, 0.65214956, 0.52278876, 0.68800545],\n",
      "       [0.5131669 , 0.75609875, 0.5220486 , 0.7860335 ],\n",
      "       [0.51958144, 0.49310073, 0.52945006, 0.5016535 ],\n",
      "       [0.55634195, 0.33849275, 0.68414026, 0.44638938],\n",
      "       [0.5519058 , 0.21998993, 0.6328254 , 0.30699682],\n",
      "       [0.5400588 , 0.46415287, 0.62246156, 0.525996  ],\n",
      "       [0.5279698 , 0.37599343, 0.5368515 , 0.39244106],\n",
      "       [0.5230423 , 0.44096047, 0.53044236, 0.44721007],\n",
      "       [0.52377564, 0.43421814, 0.53019017, 0.4401393 ],\n",
      "       [0.5319172 , 0.4055992 , 0.5506675 , 0.414152  ],\n",
      "       [0.5235289 , 0.34967718, 0.53635806, 0.35822996],\n",
      "       [0.51218003, 0.80313903, 0.5250092 , 0.8883379 ],\n",
      "       [0.52303547, 0.45494217, 0.54079896, 0.4681003 ],\n",
      "       [0.5257493 , 0.4681003 , 0.5380851 , 0.47665307],\n",
      "       [0.52278876, 0.38553306, 0.53117704, 0.40198073],\n",
      "       [0.4887421 , 0.87468636, 0.59877694, 1.        ],\n",
      "       [0.53561795, 0.48306766, 0.5440062 , 0.5037917 ],\n",
      "       [0.50429237, 0.476406  , 0.5378456 , 0.49137312],\n",
      "       [0.5215552 , 0.4694161 , 0.5274763 , 0.47599518]], dtype=float32)>, 'groundtruth_area': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_is_crowd': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_difficult': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_group_of': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_weights': <tf.Tensor: shape=(21,), dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1.], dtype=float32)>, 'groundtruth_classes': <tf.Tensor: shape=(21,), dtype=int64, numpy=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])>, 'groundtruth_image_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'original_image_spatial_shape': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([640, 640], dtype=int32)>}\n",
      "{'image': <tf.Tensor: shape=(640, 640, 3), dtype=uint8, numpy=\n",
      "array([[[159, 185, 242],\n",
      "        [161, 187, 244],\n",
      "        [163, 189, 246],\n",
      "        ...,\n",
      "        [120, 179, 247],\n",
      "        [121, 180, 248],\n",
      "        [123, 182, 250]],\n",
      "\n",
      "       [[160, 186, 243],\n",
      "        [162, 188, 245],\n",
      "        [165, 191, 248],\n",
      "        ...,\n",
      "        [120, 179, 247],\n",
      "        [119, 178, 246],\n",
      "        [120, 179, 247]],\n",
      "\n",
      "       [[155, 185, 239],\n",
      "        [154, 184, 238],\n",
      "        [154, 184, 238],\n",
      "        ...,\n",
      "        [123, 182, 250],\n",
      "        [123, 182, 250],\n",
      "        [124, 183, 251]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 71,  74,  81],\n",
      "        [ 71,  74,  81],\n",
      "        [ 73,  73,  81],\n",
      "        ...,\n",
      "        [ 38,  39,  44],\n",
      "        [ 37,  38,  43],\n",
      "        [ 37,  38,  43]],\n",
      "\n",
      "       [[ 72,  75,  82],\n",
      "        [ 73,  76,  83],\n",
      "        [ 74,  74,  82],\n",
      "        ...,\n",
      "        [ 39,  38,  44],\n",
      "        [ 37,  36,  41],\n",
      "        [ 37,  36,  41]],\n",
      "\n",
      "       [[ 73,  76,  83],\n",
      "        [ 73,  76,  83],\n",
      "        [ 73,  73,  81],\n",
      "        ...,\n",
      "        [ 39,  38,  44],\n",
      "        [ 39,  38,  43],\n",
      "        [ 38,  37,  42]]], dtype=uint8)>, 'source_id': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_70.tfrecord'>, 'key': <tf.Tensor: shape=(), dtype=string, numpy=b''>, 'filename': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_70.tfrecord'>, 'groundtruth_image_confidences': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_verified_neg_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_not_exhaustive_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_boxes': <tf.Tensor: shape=(12, 4), dtype=float32, numpy=\n",
      "array([[0.5324106 , 0.38662955, 0.5916222 , 0.4359725 ],\n",
      "       [0.52198696, 0.4971304 , 0.5374066 , 0.51160437],\n",
      "       [0.51760775, 0.49737713, 0.5264895 , 0.50132453],\n",
      "       [0.5642368 , 0.16858847, 0.72361463, 0.3222096 ],\n",
      "       [0.5400588 , 0.42802286, 0.65469897, 0.51322174],\n",
      "       [0.5366048 , 0.3643156 , 0.5755857 , 0.39523718],\n",
      "       [0.5209384 , 0.4421541 , 0.54314274, 0.46082222],\n",
      "       [0.5222953 , 0.4694161 , 0.5326573 , 0.4786268 ],\n",
      "       [0.6071652 , 0.7712306 , 0.6935154 , 0.79853374],\n",
      "       [0.53759164, 0.49014017, 0.58742803, 0.5250092 ],\n",
      "       [0.5057653 , 0.48537034, 0.53142375, 0.49787056],\n",
      "       [0.5304369 , 0.7436809 , 0.66810393, 0.78167504]], dtype=float32)>, 'groundtruth_area': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_is_crowd': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_difficult': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_group_of': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_weights': <tf.Tensor: shape=(12,), dtype=float32, numpy=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)>, 'groundtruth_classes': <tf.Tensor: shape=(12,), dtype=int64, numpy=array([1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2])>, 'groundtruth_image_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'original_image_spatial_shape': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([640, 640], dtype=int32)>}\n",
      "{'image': <tf.Tensor: shape=(640, 640, 3), dtype=uint8, numpy=\n",
      "array([[[190, 220, 255],\n",
      "        [191, 221, 255],\n",
      "        [191, 221, 255],\n",
      "        ...,\n",
      "        [ 56,  77,  80],\n",
      "        [ 63,  81,  95],\n",
      "        [ 48,  65,  85]],\n",
      "\n",
      "       [[185, 215, 253],\n",
      "        [187, 217, 253],\n",
      "        [188, 218, 252],\n",
      "        ...,\n",
      "        [ 52,  73,  74],\n",
      "        [114, 134, 145],\n",
      "        [ 45,  64,  81]],\n",
      "\n",
      "       [[179, 208, 248],\n",
      "        [181, 211, 249],\n",
      "        [183, 213, 249],\n",
      "        ...,\n",
      "        [ 44,  65,  66],\n",
      "        [ 52,  72,  79],\n",
      "        [ 46,  68,  79]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 86,  85,  93],\n",
      "        [ 85,  84,  92],\n",
      "        [ 83,  82,  90],\n",
      "        ...,\n",
      "        [ 62,  57,  64],\n",
      "        [ 65,  59,  69],\n",
      "        [ 57,  51,  61]],\n",
      "\n",
      "       [[ 85,  85,  93],\n",
      "        [ 84,  84,  92],\n",
      "        [ 84,  84,  92],\n",
      "        ...,\n",
      "        [ 62,  54,  65],\n",
      "        [ 60,  52,  63],\n",
      "        [ 58,  50,  61]],\n",
      "\n",
      "       [[ 82,  82,  90],\n",
      "        [ 83,  83,  91],\n",
      "        [ 84,  84,  92],\n",
      "        ...,\n",
      "        [ 62,  54,  65],\n",
      "        [ 57,  49,  60],\n",
      "        [ 61,  53,  64]]], dtype=uint8)>, 'source_id': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_140.tfrecord'>, 'key': <tf.Tensor: shape=(), dtype=string, numpy=b''>, 'filename': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_140.tfrecord'>, 'groundtruth_image_confidences': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_verified_neg_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_not_exhaustive_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_boxes': <tf.Tensor: shape=(21, 4), dtype=float32, numpy=\n",
      "array([[0.53586465, 0.40033597, 0.5881682 , 0.44441566],\n",
      "       [0.5250092 , 0.5024759 , 0.5398121 , 0.51398927],\n",
      "       [0.515634  , 0.5873458 , 0.51958144, 0.59425384],\n",
      "       [0.52185154, 0.498594  , 0.5307333 , 0.505502  ],\n",
      "       [0.5600427 , 0.2583927 , 0.68438697, 0.3725394 ],\n",
      "       [0.56941783, 0.10411366, 0.68093294, 0.23339224],\n",
      "       [0.5405522 , 0.46020544, 0.6347973 , 0.5286277 ],\n",
      "       [0.52624273, 0.45510665, 0.5326573 , 0.45938304],\n",
      "       [0.5274763 , 0.45148817, 0.5324106 , 0.45708036],\n",
      "       [0.5351245 , 0.39836225, 0.5652237 , 0.41349408],\n",
      "       [0.5274763 , 0.39605957, 0.53142375, 0.39869118],\n",
      "       [0.5229862 , 0.4576559 , 0.54173654, 0.47275493],\n",
      "       [0.52624273, 0.47402146, 0.5385785 , 0.48257422],\n",
      "       [0.5220486 , 0.519417  , 0.5279698 , 0.52928555],\n",
      "       [0.5287099 , 0.4133296 , 0.5351245 , 0.42484295],\n",
      "       [0.51588076, 0.59688544, 0.53611135, 0.6169516 ],\n",
      "       [0.5383318 , 0.4898112 , 0.5531347 , 0.5200749 ],\n",
      "       [0.5218019 , 0.51826566, 0.5282165 , 0.529779  ],\n",
      "       [0.50576496, 0.48331487, 0.5363572 , 0.49828213],\n",
      "       [0.52426904, 0.4784623 , 0.53068364, 0.4827387 ],\n",
      "       [0.5255026 , 0.4384945 , 0.52945006, 0.44112614]], dtype=float32)>, 'groundtruth_area': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_is_crowd': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_difficult': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_group_of': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_weights': <tf.Tensor: shape=(21,), dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1.], dtype=float32)>, 'groundtruth_classes': <tf.Tensor: shape=(21,), dtype=int64, numpy=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])>, 'groundtruth_image_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'original_image_spatial_shape': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([640, 640], dtype=int32)>}\n",
      "{'image': <tf.Tensor: shape=(640, 640, 3), dtype=uint8, numpy=\n",
      "array([[[159, 185, 234],\n",
      "        [164, 190, 239],\n",
      "        [166, 191, 245],\n",
      "        ...,\n",
      "        [117, 174, 243],\n",
      "        [116, 173, 242],\n",
      "        [118, 175, 244]],\n",
      "\n",
      "       [[159, 185, 234],\n",
      "        [160, 186, 235],\n",
      "        [160, 185, 239],\n",
      "        ...,\n",
      "        [117, 174, 243],\n",
      "        [118, 175, 244],\n",
      "        [120, 177, 246]],\n",
      "\n",
      "       [[158, 181, 231],\n",
      "        [161, 184, 234],\n",
      "        [165, 188, 242],\n",
      "        ...,\n",
      "        [119, 176, 245],\n",
      "        [120, 177, 246],\n",
      "        [122, 179, 248]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 72,  73,  78],\n",
      "        [ 72,  73,  78],\n",
      "        [ 77,  76,  82],\n",
      "        ...,\n",
      "        [ 29,  34,  37],\n",
      "        [ 30,  35,  38],\n",
      "        [ 22,  27,  30]],\n",
      "\n",
      "       [[ 70,  73,  78],\n",
      "        [ 71,  74,  79],\n",
      "        [ 75,  76,  81],\n",
      "        ...,\n",
      "        [ 37,  40,  45],\n",
      "        [ 32,  35,  40],\n",
      "        [ 27,  30,  35]],\n",
      "\n",
      "       [[ 69,  72,  77],\n",
      "        [ 70,  73,  78],\n",
      "        [ 71,  72,  77],\n",
      "        ...,\n",
      "        [ 37,  40,  45],\n",
      "        [ 28,  31,  36],\n",
      "        [ 25,  28,  33]]], dtype=uint8)>, 'source_id': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_0.tfrecord'>, 'key': <tf.Tensor: shape=(), dtype=string, numpy=b''>, 'filename': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_0.tfrecord'>, 'groundtruth_image_confidences': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_verified_neg_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_not_exhaustive_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_boxes': <tf.Tensor: shape=(14, 4), dtype=float32, numpy=\n",
      "array([[0.5331508 , 0.39836225, 0.59186894, 0.44507357],\n",
      "       [0.52377564, 0.4967192 , 0.54104567, 0.5131669 ],\n",
      "       [0.51958144, 0.49392313, 0.52945006, 0.5008311 ],\n",
      "       [0.56818426, 0.1761544 , 0.7463124 , 0.34490734],\n",
      "       [0.53783834, 0.46365944, 0.6365243 , 0.53306854],\n",
      "       [0.5220486 , 0.47221223, 0.5269829 , 0.4764886 ],\n",
      "       [0.5400588 , 0.3495127 , 0.5800266 , 0.39128974],\n",
      "       [0.5215552 , 0.561194  , 0.5462267 , 0.5677731 ],\n",
      "       [0.5252559 , 0.4329023 , 0.5514077 , 0.4519816 ],\n",
      "       [0.5255026 , 0.46415287, 0.5383318 , 0.47599518],\n",
      "       [0.53043693, 0.5431016 , 0.53635806, 0.54704905],\n",
      "       [0.53068364, 0.55116093, 0.5390719 , 0.5554373 ],\n",
      "       [0.5094662 , 0.5037917 , 0.52969676, 0.53109485],\n",
      "       [0.5218019 , 0.5416213 , 0.5370982 , 0.5485293 ]], dtype=float32)>, 'groundtruth_area': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_is_crowd': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_difficult': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_group_of': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_weights': <tf.Tensor: shape=(14,), dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, 'groundtruth_classes': <tf.Tensor: shape=(14,), dtype=int64, numpy=array([1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2])>, 'groundtruth_image_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'original_image_spatial_shape': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([640, 640], dtype=int32)>}\n",
      "{'image': <tf.Tensor: shape=(640, 640, 3), dtype=uint8, numpy=\n",
      "array([[[203, 224, 251],\n",
      "        [202, 224, 248],\n",
      "        [204, 226, 250],\n",
      "        ...,\n",
      "        [ 37,  51,  54],\n",
      "        [ 22,  37,  40],\n",
      "        [ 18,  34,  34]],\n",
      "\n",
      "       [[202, 226, 254],\n",
      "        [202, 226, 252],\n",
      "        [203, 227, 251],\n",
      "        ...,\n",
      "        [ 36,  50,  53],\n",
      "        [ 27,  42,  45],\n",
      "        [ 24,  40,  40]],\n",
      "\n",
      "       [[198, 223, 253],\n",
      "        [201, 227, 254],\n",
      "        [200, 226, 253],\n",
      "        ...,\n",
      "        [ 30,  44,  47],\n",
      "        [ 24,  39,  42],\n",
      "        [ 26,  42,  42]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 73,  76,  85],\n",
      "        [ 72,  75,  84],\n",
      "        [ 71,  74,  83],\n",
      "        ...,\n",
      "        [ 49,  48,  56],\n",
      "        [ 47,  46,  54],\n",
      "        [ 51,  50,  58]],\n",
      "\n",
      "       [[ 72,  76,  85],\n",
      "        [ 71,  75,  84],\n",
      "        [ 70,  74,  83],\n",
      "        ...,\n",
      "        [ 48,  45,  52],\n",
      "        [ 53,  48,  55],\n",
      "        [ 52,  47,  54]],\n",
      "\n",
      "       [[ 70,  74,  83],\n",
      "        [ 70,  74,  83],\n",
      "        [ 69,  73,  82],\n",
      "        ...,\n",
      "        [ 47,  42,  49],\n",
      "        [ 53,  46,  54],\n",
      "        [ 55,  48,  56]]], dtype=uint8)>, 'source_id': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_130.tfrecord'>, 'key': <tf.Tensor: shape=(), dtype=string, numpy=b''>, 'filename': <tf.Tensor: shape=(), dtype=string, numpy=b'segment-1005081002024129653_5313_150_5333_150_with_camera_labels_130.tfrecord'>, 'groundtruth_image_confidences': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_verified_neg_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_not_exhaustive_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_boxes': <tf.Tensor: shape=(15, 4), dtype=float32, numpy=\n",
      "array([[0.5351245 , 0.39704642, 0.5898952 , 0.43981034],\n",
      "       [0.5250092 , 0.49935085, 0.5398121 , 0.5118511 ],\n",
      "       [0.52254206, 0.49490997, 0.53142375, 0.50313383],\n",
      "       [0.56094784, 0.25038704, 0.6890746 , 0.3647543 ],\n",
      "       [0.5791641 , 0.05361563, 0.70227534, 0.20263237],\n",
      "       [0.54252595, 0.45066577, 0.64170533, 0.52237755],\n",
      "       [0.5380851 , 0.38931602, 0.56917113, 0.40675053],\n",
      "       [0.5211321 , 0.45376712, 0.5405169 , 0.46889895],\n",
      "       [0.5272296 , 0.47040296, 0.53759164, 0.47961366],\n",
      "       [0.5279698 , 0.41513884, 0.5338909 , 0.42434952],\n",
      "       [0.5213085 , 0.5799444 , 0.5336442 , 0.589155  ],\n",
      "       [0.5380851 , 0.4870151 , 0.56719744, 0.5162919 ],\n",
      "       [0.52303547, 0.50198245, 0.5269829 , 0.5059299 ],\n",
      "       [0.5074924 , 0.48109394, 0.53759164, 0.49589685],\n",
      "       [0.52895665, 0.45296845, 0.5329041 , 0.45560008]], dtype=float32)>, 'groundtruth_area': <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>, 'groundtruth_is_crowd': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_difficult': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'groundtruth_group_of': <tf.Tensor: shape=(0,), dtype=bool, numpy=array([], dtype=bool)>, 'groundtruth_weights': <tf.Tensor: shape=(15,), dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "      dtype=float32)>, 'groundtruth_classes': <tf.Tensor: shape=(15,), dtype=int64, numpy=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])>, 'groundtruth_image_classes': <tf.Tensor: shape=(0,), dtype=int64, numpy=array([], dtype=int64)>, 'original_image_spatial_shape': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([640, 640], dtype=int32)>}\n"
     ]
    }
   ],
   "source": [
    "##### 表示確認\n",
    "# batch_data[\"groundtruth_classes\"] in batch\n",
    "#print(batch[0])\n",
    "# print(batch[\"groundtruth_classes\"] )\n",
    "\n",
    "for idx, batch_data in enumerate(batch):\n",
    "    print(batch_data)\n",
    "#    gt_classes = batch_data[\"groundtruth_classes\"].numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1 1 1 1 1 1 1 2 2 1 1 2], shape=(13,), dtype=int64)\n",
      "1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1bece1c586be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgt_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgt_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mcnt_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgt_classes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "##### カラーマップ\n",
    "clr_map={1:'blue',2:'green',4:'red'}\n",
    "\n",
    "##### ラベル設定\n",
    "class_names = {1:'vehicle', 2:'pedestrian', 4:'cyclist'}\n",
    "\n",
    "##### ラベル数カウント\n",
    "batch = dataset.take(100)\n",
    "##### 0:'vehicle', 1:'pedestrian', 2:'cyclist'\n",
    "cnt_class = {1:0, 2:0, 4:0}\n",
    "\n",
    "for idx, batch_data in enumerate(batch):\n",
    "    gt_classes = batch_data[\"groundtruth_classes\"]\n",
    "    print(gt_classes)\n",
    "    gt_classes = gt_classes.numpy()\n",
    "    for gt_class in gt_classes:\n",
    "        print(gt_class)\n",
    "        cnt_class[gt_classes] += 1\n",
    "\n",
    "print(cnt_class)\n",
    "\n",
    "##### グラフ表示\n",
    "plt.bar(class_names.values, cnt_class.values, clr_map.values,width=0.4)\n",
    "plt.xlabel(\"class_names\")\n",
    "plt.ylabel(\"cnt_class\")\n",
    "plt.title(\"counts of object classes on waymo dataset\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected Ptr<cv::UMat> for argument 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-71d787ce83ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mvalue_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mhsv_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2HSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mhue_means\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0msaturation_means\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected Ptr<cv::UMat> for argument 'src'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "##### 画像群取得\n",
    "images = []\n",
    "for idx, batch_data in enumerate(batch):\n",
    "    img = batch_data[\"image\"]\n",
    "    images.append(img)\n",
    "range = (0, 255)\n",
    "        \n",
    "##### RGBのヒストグラム\n",
    "red_means = []\n",
    "blue_means = []\n",
    "green_means = []\n",
    "for img in images:\n",
    "#    bgr_image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    img = cv2.imread(img)\n",
    "    red_means.append(img[:, :, 0])\n",
    "    blue_means.append(img[:, :, 1])\n",
    "    green_means.append(img[:, :, 2])\n",
    "    \n",
    "##### HSVのヒストグラム\n",
    "hue_means = []\n",
    "saturation_means = []\n",
    "value_means = []\n",
    "for img in images:\n",
    "    img = cv2.imread(img)\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    hue_means.append(img[:, :, 0])\n",
    "    saturation_means.append(img[:, :, 1])\n",
    "    value_means.append(img[:, :, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x must have 2 or fewer dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a726555d384e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mred_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/virtual_envs/sdc-c1-gpu-augment/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, data, **kwargs)\u001b[0m\n\u001b[1;32m   2825\u001b[0m         \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m         \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2827\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/virtual_envs/sdc-c1-gpu-augment/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/virtual_envs/sdc-c1-gpu-augment/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mhist\u001b[0;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001b[0m\n\u001b[1;32m   6649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6650\u001b[0m         \u001b[0;31m# Massage 'x' for processing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6651\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reshape_2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6652\u001b[0m         \u001b[0mnx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# number of datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/virtual_envs/sdc-c1-gpu-augment/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_reshape_2D\u001b[0;34m(X, name)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnd\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{name} must have 2 or fewer dimensions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1434\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x must have 2 or fewer dimensions"
     ]
    }
   ],
   "source": [
    "plt.hist(red_means, range=range, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(blue_means, range=range, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(green_means, range=range, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hue_means, range=range, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(saturation_means, range=range, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(value_means, range=range, bins=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
